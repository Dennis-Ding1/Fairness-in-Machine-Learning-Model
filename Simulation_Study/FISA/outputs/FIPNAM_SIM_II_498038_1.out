created virtual environment CPython3.11.5.final.0-64 in 319ms
  creator CPython3Posix(dest=/dev/shm/slurm.dinghaoc.498115/env, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/tmp/tmp03b1cxtn)
    added seed packages: pip==23.2.1, setuptools==68.0.0, wheel==0.41.1
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Starting experiment: FIPNAM on SIMULATED_II
Data file: ../data/data_II.csv
Batch size: 128, Learning rate: 0.01, Epochs: 40
Lambda (fairness-accuracy trade-off): 0.01
------------------------------------------------------------
Loading and preprocessing data...
Using 5 X covariates: ['age', 'LOS', 'eGFR', 'Hemoglobin', 'CCI']
Computing pseudo values for training data...
  Computing survival function for 4474 samples...
  Computing leave-one-out survival for 4474 samples (this may take a while)...
  Processing sample 500/4474 (11.2%)...
  Processing sample 1000/4474 (22.4%)...
  Processing sample 1500/4474 (33.5%)...
  Processing sample 2000/4474 (44.7%)...
  Processing sample 2500/4474 (55.9%)...
  Processing sample 3000/4474 (67.1%)...
  Processing sample 3500/4474 (78.2%)...
  Processing sample 4000/4474 (89.4%)...
  Finalizing pseudo values...
Computing pseudo values for validation data...
  Computing survival function for 1120 samples...
  Computing leave-one-out survival for 1120 samples (this may take a while)...
  Processing sample 500/1120 (44.6%)...
  Processing sample 1000/1120 (89.3%)...
  Finalizing pseudo values...
Computing pseudo values for test data...
  Computing survival function for 1400 samples...
  Computing leave-one-out survival for 1400 samples (this may take a while)...
  Processing sample 500/1400 (35.7%)...
  Processing sample 1000/1400 (71.4%)...
  Finalizing pseudo values...
Pseudo values computation completed!
Fairness parameters - Scale: 0.01 (FIXED), Lambda: 0.01
Epoch 1
-------------------------------
  Loss breakdown - Pseudo: 0.266222, Fairness: 0.206698 (λ=0.010), Total: 0.268289
Epoch 1:
  Train   - Loss: 0.268289, C-index: 0.483811, Brier: 0.230152, AUC: 0.520154
  Valid   - Loss: 0.211046, C-index: 0.487446, Brier: 0.228020, AUC: 0.527456
Epoch 2
-------------------------------
  Loss breakdown - Pseudo: 0.226555, Fairness: 0.104538 (λ=0.010), Total: 0.227600
Epoch 2:
  Train   - Loss: 0.227600
  Valid   - Loss: 0.210641
Epoch 3
-------------------------------
  Loss breakdown - Pseudo: 0.223436, Fairness: 0.096159 (λ=0.010), Total: 0.224397
Epoch 3:
  Train   - Loss: 0.224397
  Valid   - Loss: 0.207919
Epoch 4
-------------------------------
  Loss breakdown - Pseudo: 0.222252, Fairness: 0.092922 (λ=0.010), Total: 0.223182
Epoch 4:
  Train   - Loss: 0.223182, C-index: 0.530235, Brier: 0.227773, AUC: 0.511138
  Valid   - Loss: 0.206307, C-index: 0.522378, Brier: 0.223572, AUC: 0.510714
Epoch 5
-------------------------------
  Loss breakdown - Pseudo: 0.221155, Fairness: 0.090827 (λ=0.010), Total: 0.222064
Epoch 5:
  Train   - Loss: 0.222064
  Valid   - Loss: 0.206237
Epoch 6
-------------------------------
  Loss breakdown - Pseudo: 0.221101, Fairness: 0.093539 (λ=0.010), Total: 0.222036
Epoch 6:
  Train   - Loss: 0.222036
  Valid   - Loss: 0.206940
Counter 1 of 8
Epoch 7
-------------------------------
  Loss breakdown - Pseudo: 0.219904, Fairness: 0.091816 (λ=0.010), Total: 0.220822
Epoch 7:
  Train   - Loss: 0.220822, C-index: 0.567269, Brier: 0.227996, AUC: 0.577214
  Valid   - Loss: 0.207645, C-index: 0.552682, Brier: 0.224454, AUC: 0.554307
Counter 2 of 8
Epoch 8
-------------------------------
  Loss breakdown - Pseudo: 0.220622, Fairness: 0.089569 (λ=0.010), Total: 0.221518
Epoch 8:
  Train   - Loss: 0.221518
  Valid   - Loss: 0.207760
Counter 3 of 8
Epoch 9
-------------------------------
  Loss breakdown - Pseudo: 0.221130, Fairness: 0.087657 (λ=0.010), Total: 0.222006
Epoch 9:
  Train   - Loss: 0.222006
  Valid   - Loss: 0.208292
Counter 4 of 8
Epoch 10
-------------------------------
  Loss breakdown - Pseudo: 0.220395, Fairness: 0.086985 (λ=0.010), Total: 0.221265
Epoch 10:
  Train   - Loss: 0.221265, C-index: 0.586763, Brier: 0.227643, AUC: 0.519455
  Valid   - Loss: 0.206659, C-index: 0.582063, Brier: 0.223511, AUC: 0.512793
Counter 5 of 8
Epoch 11
-------------------------------
  Loss breakdown - Pseudo: 0.220769, Fairness: 0.086029 (λ=0.010), Total: 0.221629
Epoch 11:
  Train   - Loss: 0.221629
  Valid   - Loss: 0.206562
Counter 6 of 8
Epoch 12
-------------------------------
  Loss breakdown - Pseudo: 0.220340, Fairness: 0.086638 (λ=0.010), Total: 0.221206
Epoch 12:
  Train   - Loss: 0.221206
  Valid   - Loss: 0.206179
Epoch 13
-------------------------------
  Loss breakdown - Pseudo: 0.219953, Fairness: 0.085773 (λ=0.010), Total: 0.220811
Epoch 13:
  Train   - Loss: 0.220811, C-index: 0.569349, Brier: 0.228302, AUC: 0.525190
  Valid   - Loss: 0.207343, C-index: 0.570159, Brier: 0.224532, AUC: 0.515442
Counter 1 of 8
Epoch 14
-------------------------------
  Loss breakdown - Pseudo: 0.219593, Fairness: 0.088711 (λ=0.010), Total: 0.220480
Epoch 14:
  Train   - Loss: 0.220480
  Valid   - Loss: 0.207097
Counter 2 of 8
Epoch 15
-------------------------------
  Loss breakdown - Pseudo: 0.219340, Fairness: 0.084712 (λ=0.010), Total: 0.220187
Epoch 15:
  Train   - Loss: 0.220187
  Valid   - Loss: 0.206641
Counter 3 of 8
Epoch 16
-------------------------------
  Loss breakdown - Pseudo: 0.218467, Fairness: 0.085206 (λ=0.010), Total: 0.219319
Epoch 16:
  Train   - Loss: 0.219319, C-index: 0.584580, Brier: 0.226528, AUC: 0.579398
  Valid   - Loss: 0.205550, C-index: 0.580093, Brier: 0.222098, AUC: 0.571768
Epoch 17
-------------------------------
  Loss breakdown - Pseudo: 0.219577, Fairness: 0.091144 (λ=0.010), Total: 0.220488
Epoch 17:
  Train   - Loss: 0.220488
  Valid   - Loss: 0.206281
Counter 1 of 8
Epoch 18
-------------------------------
  Loss breakdown - Pseudo: 0.220894, Fairness: 0.088988 (λ=0.010), Total: 0.221783
Epoch 18:
  Train   - Loss: 0.221783
  Valid   - Loss: 0.207390
Counter 2 of 8
Epoch 19
-------------------------------
  Loss breakdown - Pseudo: 0.220286, Fairness: 0.084895 (λ=0.010), Total: 0.221135
Epoch 19:
  Train   - Loss: 0.221135, C-index: 0.545778, Brier: 0.228041, AUC: 0.513469
  Valid   - Loss: 0.206928, C-index: 0.538182, Brier: 0.223937, AUC: 0.507229
Counter 3 of 8
Epoch 20
-------------------------------
  Loss breakdown - Pseudo: 0.219905, Fairness: 0.083339 (λ=0.010), Total: 0.220738
Epoch 20:
  Train   - Loss: 0.220738
  Valid   - Loss: 0.206690
Counter 4 of 8
Epoch 21
-------------------------------
  Loss breakdown - Pseudo: 0.219979, Fairness: 0.084196 (λ=0.010), Total: 0.220821
Epoch 21:
  Train   - Loss: 0.220821
  Valid   - Loss: 0.206829
Counter 5 of 8
Epoch 22
-------------------------------
  Loss breakdown - Pseudo: 0.219906, Fairness: 0.082628 (λ=0.010), Total: 0.220732
Epoch 22:
  Train   - Loss: 0.220732, C-index: 0.517140, Brier: 0.227892, AUC: 0.506934
  Valid   - Loss: 0.206656, C-index: 0.500606, Brier: 0.223452, AUC: 0.488195
Counter 6 of 8
Epoch 23
-------------------------------
  Loss breakdown - Pseudo: 0.218816, Fairness: 0.082335 (λ=0.010), Total: 0.219639
Epoch 23:
  Train   - Loss: 0.219639
  Valid   - Loss: 0.207512
Counter 7 of 8
Epoch 24
-------------------------------
  Loss breakdown - Pseudo: 0.221444, Fairness: 0.083863 (λ=0.010), Total: 0.222282
Epoch 24:
  Train   - Loss: 0.222282
  Valid   - Loss: 0.207670
Counter 8 of 8
Epoch 25
-------------------------------
  Loss breakdown - Pseudo: 0.220843, Fairness: 0.082487 (λ=0.010), Total: 0.221668
Epoch 25:
  Train   - Loss: 0.221668, C-index: 0.554211, Brier: 0.227803, AUC: 0.523981
  Valid   - Loss: 0.206845, C-index: 0.541314, Brier: 0.223681, AUC: 0.512883
Counter 9 of 8
Early stopping with best_val_loss:  0.20555011928081512
Done!
Your result is ready!!! Saved to: ./Results/Results_FIPNAM_SIMULATED_II_lambda_0_01.csv
Loss plot saved to: ./Results/Results_FIPNAM_SIMULATED_II_lambda_0_01.png

scontrol show job 498115
JobId=498115 ArrayJobId=498038 ArrayTaskId=1 JobName=FIPNAM_SIM_II
   UserId=dinghaoc(3151984) GroupId=dinghaoc(3151984) MCS_label=N/A
   Priority=595559 Nice=0 Account=def-agoldenb-ab QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=01:55:19 TimeLimit=10:00:00 TimeMin=N/A
   SubmitTime=2025-11-15T22:17:13 EligibleTime=2025-11-15T22:17:14
   AccrueTime=2025-11-15T22:17:14
   StartTime=2025-11-15T22:46:47 EndTime=2025-11-16T00:42:06 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-15T22:46:47 Scheduler=Main
   Partition=compute AllocNode:Sid=tri-login03:444166
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=tri0833
   BatchHost=tri0833
   NumNodes=1 NumCPUs=192 NumTasks=1 CPUs/Task=10 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=10,mem=767000M,node=1,billing=10
   AllocTRES=cpu=192,mem=767000M,node=1,billing=192
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=10 MinMemoryNode=0 MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/dinghaoc/Fairness-in-Machine-Learning-Model/Simulation_Study/FISA/run_FIPNAM_SIM_II.slurm
   WorkDir=/scratch/dinghaoc/Fairness-in-Machine-Learning-Model/Simulation_Study/FISA
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L run_FIPNAM_SIM_II.slurm 
   StdErr=/scratch/dinghaoc/Fairness-in-Machine-Learning-Model/Simulation_Study/FISA/outputs/FIPNAM_SIM_II_498038_1.err
   StdIn=/dev/null
   StdOut=/scratch/dinghaoc/Fairness-in-Machine-Learning-Model/Simulation_Study/FISA/outputs/FIPNAM_SIM_II_498038_1.out
   TresPerTask=cpu=10
   

sacct -j 498115
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
498038_1     FIPNAM_SI+ def-agold+   01:55:19                         00:00:00   00:00:00      0:0 
498038_1.ba+      batch def-agold+   01:55:19                         00:00:00   00:00:00      0:0 
498038_1.ex+     extern def-agold+   01:55:19                         00:00:00   00:00:00      0:0 

