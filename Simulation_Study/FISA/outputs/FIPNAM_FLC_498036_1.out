created virtual environment CPython3.11.5.final.0-64 in 323ms
  creator CPython3Posix(dest=/dev/shm/slurm.dinghaoc.498111/env, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/tmp/tmpbrpril_h)
    added seed packages: pip==23.2.1, setuptools==68.0.0, wheel==0.41.1
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Starting experiment: FIPNAM on FLChain
Data file: Data/FLChain/flchain.csv
Batch size: 128, Learning rate: 0.01, Epochs: 40
Lambda (fairness-accuracy trade-off): 0.01
------------------------------------------------------------
Loading and preprocessing data...
Computing pseudo values for training data...
  Computing survival function for 4171 samples...
  Computing leave-one-out survival for 4171 samples (this may take a while)...
  Processing sample 500/4171 (12.0%)...
  Processing sample 1000/4171 (24.0%)...
  Processing sample 1500/4171 (36.0%)...
  Processing sample 2000/4171 (48.0%)...
  Processing sample 2500/4171 (59.9%)...
  Processing sample 3000/4171 (71.9%)...
  Processing sample 3500/4171 (83.9%)...
  Processing sample 4000/4171 (95.9%)...
  Finalizing pseudo values...
Computing pseudo values for validation data...
  Computing survival function for 1044 samples...
  Computing leave-one-out survival for 1044 samples (this may take a while)...
  Processing sample 500/1044 (47.9%)...
  Processing sample 1000/1044 (95.8%)...
  Finalizing pseudo values...
Computing pseudo values for test data...
  Computing survival function for 1304 samples...
  Computing leave-one-out survival for 1304 samples (this may take a while)...
  Processing sample 500/1304 (38.3%)...
  Processing sample 1000/1304 (76.7%)...
  Finalizing pseudo values...
Pseudo values computation completed!
Fairness parameters - Scale: 0.01 (FIXED), Lambda: 0.01
Epoch 1
-------------------------------
  Loss breakdown - Pseudo: 0.216221, Fairness: 0.179400 (λ=0.010), Total: 0.218015
Epoch 1:
  Train   - Loss: 0.218015, C-index: 0.734655, Brier: 0.164130, AUC: 0.769688
  Valid   - Loss: 0.165850, C-index: 0.740975, Brier: 0.165525, AUC: 0.775967
Epoch 2
-------------------------------
  Loss breakdown - Pseudo: 0.196385, Fairness: 0.178792 (λ=0.010), Total: 0.198173
Epoch 2:
  Train   - Loss: 0.198173
  Valid   - Loss: 0.157598
Epoch 3
-------------------------------
  Loss breakdown - Pseudo: 0.194637, Fairness: 0.167902 (λ=0.010), Total: 0.196316
Epoch 3:
  Train   - Loss: 0.196316
  Valid   - Loss: 0.156191
Epoch 4
-------------------------------
  Loss breakdown - Pseudo: 0.194586, Fairness: 0.158897 (λ=0.010), Total: 0.196175
Epoch 4:
  Train   - Loss: 0.196175, C-index: 0.749106, Brier: 0.160831, AUC: 0.786209
  Valid   - Loss: 0.159665, C-index: 0.749385, Brier: 0.162315, AUC: 0.786899
Counter 1 of 8
Epoch 5
-------------------------------
  Loss breakdown - Pseudo: 0.198000, Fairness: 0.149985 (λ=0.010), Total: 0.199500
Epoch 5:
  Train   - Loss: 0.199500
  Valid   - Loss: 0.158900
Counter 2 of 8
Epoch 6
-------------------------------
  Loss breakdown - Pseudo: 0.192415, Fairness: 0.159457 (λ=0.010), Total: 0.194010
Epoch 6:
  Train   - Loss: 0.194010
  Valid   - Loss: 0.175807
Counter 3 of 8
Epoch 7
-------------------------------
  Loss breakdown - Pseudo: 0.191373, Fairness: 0.155029 (λ=0.010), Total: 0.192923
Epoch 7:
  Train   - Loss: 0.192923, C-index: 0.749494, Brier: 0.169391, AUC: 0.785532
  Valid   - Loss: 0.172375, C-index: 0.750418, Brier: 0.170806, AUC: 0.791256
Counter 4 of 8
Epoch 8
-------------------------------
  Loss breakdown - Pseudo: 0.193547, Fairness: 0.149926 (λ=0.010), Total: 0.195046
Epoch 8:
  Train   - Loss: 0.195046
  Valid   - Loss: 0.169370
Counter 5 of 8
Epoch 9
-------------------------------
  Loss breakdown - Pseudo: 0.192864, Fairness: 0.172926 (λ=0.010), Total: 0.194594
Epoch 9:
  Train   - Loss: 0.194594
  Valid   - Loss: 0.166245
Counter 6 of 8
Epoch 10
-------------------------------
  Loss breakdown - Pseudo: 0.190444, Fairness: 0.162835 (λ=0.010), Total: 0.192072
Epoch 10:
  Train   - Loss: 0.192072, C-index: 0.720443, Brier: 0.168737, AUC: 0.754365
  Valid   - Loss: 0.172639, C-index: 0.716225, Brier: 0.171162, AUC: 0.748665
Counter 7 of 8
Epoch 11
-------------------------------
  Loss breakdown - Pseudo: 0.191520, Fairness: 0.143653 (λ=0.010), Total: 0.192957
Epoch 11:
  Train   - Loss: 0.192957
  Valid   - Loss: 0.148180
Epoch 12
-------------------------------
  Loss breakdown - Pseudo: 0.192877, Fairness: 0.150211 (λ=0.010), Total: 0.194379
Epoch 12:
  Train   - Loss: 0.194379
  Valid   - Loss: 0.168478
Counter 1 of 8
Epoch 13
-------------------------------
  Loss breakdown - Pseudo: 0.191035, Fairness: 0.144074 (λ=0.010), Total: 0.192476
Epoch 13:
  Train   - Loss: 0.192476, C-index: 0.746708, Brier: 0.163505, AUC: 0.785015
  Valid   - Loss: 0.171211, C-index: 0.745562, Brier: 0.164178, AUC: 0.784807
Counter 2 of 8
Epoch 14
-------------------------------
  Loss breakdown - Pseudo: 0.189818, Fairness: 0.142530 (λ=0.010), Total: 0.191243
Epoch 14:
  Train   - Loss: 0.191243
  Valid   - Loss: 0.171822
Counter 3 of 8
Epoch 15
-------------------------------
  Loss breakdown - Pseudo: 0.192816, Fairness: 0.171321 (λ=0.010), Total: 0.194529
Epoch 15:
  Train   - Loss: 0.194529
  Valid   - Loss: 0.175530
Counter 4 of 8
Epoch 16
-------------------------------
  Loss breakdown - Pseudo: 0.194047, Fairness: 0.148237 (λ=0.010), Total: 0.195529
Epoch 16:
  Train   - Loss: 0.195529, C-index: 0.748308, Brier: 0.153448, AUC: 0.787468
  Valid   - Loss: 0.150979, C-index: 0.746556, Brier: 0.153046, AUC: 0.787834
Counter 5 of 8
Epoch 17
-------------------------------
  Loss breakdown - Pseudo: 0.193062, Fairness: 0.152423 (λ=0.010), Total: 0.194586
Epoch 17:
  Train   - Loss: 0.194586
  Valid   - Loss: 0.174037
Counter 6 of 8
Epoch 18
-------------------------------
  Loss breakdown - Pseudo: 0.191499, Fairness: 0.138651 (λ=0.010), Total: 0.192886
Epoch 18:
  Train   - Loss: 0.192886
  Valid   - Loss: 0.169820
Counter 7 of 8
Epoch 19
-------------------------------
  Loss breakdown - Pseudo: 0.193898, Fairness: 0.139657 (λ=0.010), Total: 0.195294
Epoch 19:
  Train   - Loss: 0.195294, C-index: 0.729643, Brier: 0.176708, AUC: 0.773598
  Valid   - Loss: 0.175518, C-index: 0.723195, Brier: 0.178758, AUC: 0.770088
Counter 8 of 8
Epoch 20
-------------------------------
  Loss breakdown - Pseudo: 0.195096, Fairness: 0.146434 (λ=0.010), Total: 0.196561
Epoch 20:
  Train   - Loss: 0.196561
  Valid   - Loss: 0.181872
Counter 9 of 8
Early stopping with best_val_loss:  0.14817953730622926
Done!
Your result is ready!!! Saved to: ./Results/Results_FIPNAM_FLChain_lambda_0_01.csv
Loss plot saved to: ./Results/Results_FIPNAM_FLChain_lambda_0_01.png

scontrol show job 498111
JobId=498111 ArrayJobId=498036 ArrayTaskId=1 JobName=FIPNAM_FLC
   UserId=dinghaoc(3151984) GroupId=dinghaoc(3151984) MCS_label=N/A
   Priority=595559 Nice=0 Account=def-agoldenb-ab QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=01:52:23 TimeLimit=10:00:00 TimeMin=N/A
   SubmitTime=2025-11-15T22:17:13 EligibleTime=2025-11-15T22:17:14
   AccrueTime=2025-11-15T22:17:14
   StartTime=2025-11-15T22:46:47 EndTime=2025-11-16T00:39:10 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2025-11-15T22:46:47 Scheduler=Main
   Partition=compute AllocNode:Sid=tri-login03:444166
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=tri0535
   BatchHost=tri0535
   NumNodes=1 NumCPUs=192 NumTasks=1 CPUs/Task=10 ReqB:S:C:T=0:0:*:*
   ReqTRES=cpu=10,mem=767000M,node=1,billing=10
   AllocTRES=cpu=192,mem=767000M,node=1,billing=192
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*
   MinCPUsNode=10 MinMemoryNode=0 MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/scratch/dinghaoc/Fairness-in-Machine-Learning-Model/Simulation_Study/FISA/run_FIPNAM_FLC.slurm
   WorkDir=/scratch/dinghaoc/Fairness-in-Machine-Learning-Model/Simulation_Study/FISA
   Comment=/opt/slurm/bin/sbatch --export=NONE --get-user-env=L run_FIPNAM_FLC.slurm 
   StdErr=/scratch/dinghaoc/Fairness-in-Machine-Learning-Model/Simulation_Study/FISA/outputs/FIPNAM_FLC_498036_1.err
   StdIn=/dev/null
   StdOut=/scratch/dinghaoc/Fairness-in-Machine-Learning-Model/Simulation_Study/FISA/outputs/FIPNAM_FLC_498036_1.out
   TresPerTask=cpu=10
   

sacct -j 498111
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
498036_1     FIPNAM_FLC def-agold+   01:52:23                         00:00:00   00:00:00      0:0 
498036_1.ba+      batch def-agold+   01:52:23                         00:00:00   00:00:00      0:0 
498036_1.ex+     extern def-agold+   01:52:23                         00:00:00   00:00:00      0:0 

